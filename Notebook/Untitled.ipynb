{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6915a0b4",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d386bc2",
   "metadata": {},
   "source": [
    "1 - Generar script para levantar el JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "034e41a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ad68ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_json(file):\n",
    "    with open(file, 'r') as file2:\n",
    "    \n",
    "        data = json.load(file2)\n",
    "        df = pd.DataFrame([data])\n",
    "        df.to_csv(\"df.csv\", index=False)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb4a5812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDW58</td>\n",
       "      <td>20.75</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.007565</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>107.8622</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility    Item_Type  \\\n",
       "0           FDW58        20.75          Low Fat         0.007565  Snack Foods   \n",
       "\n",
       "   Item_MRP Outlet_Identifier  Outlet_Establishment_Year Outlet_Size  \\\n",
       "0  107.8622            OUT049                       1999      Medium   \n",
       "\n",
       "  Outlet_Location_Type        Outlet_Type  \n",
       "0               Tier 1  Supermarket Type1  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = up_json(\"example.json\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89dcb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1b9423cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_preprocesing(data_train, data_test):\n",
    "    \n",
    "    # Identificando la data de train y de test, para posteriormente unión y separación\n",
    "    data_train['Set'] = 'train'\n",
    "    data_test['Set'] = 'test'\n",
    "    data = pd.concat([data_train, data_test], ignore_index=True, sort=False)\n",
    "    \n",
    "    #Feature engineering años del establecimiento\n",
    "    \n",
    "    data['Outlet_Establishment_Year'] = 2020 - data['Outlet_Establishment_Year']\n",
    "    \n",
    "    #LIMPIEZA: Unificando etiquetas para 'Item_Fat_Content'\n",
    "    \n",
    "    data['Item_Fat_Content'] = data['Item_Fat_Content'].replace({'low fat':  'Low Fat', 'LF': 'Low Fat', 'reg': 'Regular'})\n",
    "    \n",
    "    #LIMPIEZA: de faltantes en el peso de los productos\n",
    "    \n",
    "    productos = list(data[data['Item_Weight'].isnull()]['Item_Identifier'].unique())\n",
    "    for producto in productos:\n",
    "        moda = (data[data['Item_Identifier'] == producto][['Item_Weight']]).mode().iloc[0,0]\n",
    "        data.loc[data['Item_Identifier'] == producto, 'Item_Weight'] = moda\n",
    "    \n",
    "    #LIMPIEZA: de faltantes en el tamaño de las tiendas\n",
    "    outlets = list(data[data['Outlet_Size'].isnull()]['Outlet_Identifier'].unique())\n",
    "    for outlet in outlets:\n",
    "        data.loc[data['Outlet_Identifier'] == outlet, 'Outlet_Size'] =  'Small'\n",
    "    \n",
    "    # FEATURES ENGINEERING: creando categorías para 'Item_Type'\n",
    "    data['Item_Type'] = data['Item_Type'].replace({'Others': 'Non perishable', 'Health and Hygiene': 'Non perishable', 'Household': 'Non perishable',\n",
    "     'Seafood': 'Meats', 'Meat': 'Meats',\n",
    "     'Baking Goods': 'Processed Foods', 'Frozen Foods': 'Processed Foods', 'Canned': 'Processed Foods', 'Snack Foods': 'Processed Foods',\n",
    "     'Breads': 'Starchy Foods', 'Breakfast': 'Starchy Foods',\n",
    "     'Soft Drinks': 'Drinks', 'Hard Drinks': 'Drinks', 'Dairy': 'Drinks'})\n",
    "\n",
    "    # FEATURES ENGINEERING: asignación de nueva categorías para 'Item_Fat_Content'\n",
    "    data.loc[data['Item_Type'] == 'Non perishable', 'Item_Fat_Content'] = 'NA'\n",
    "    \n",
    "    #FEATURES ENGINEERING: Codificando los niveles de precios de los productos\n",
    "    pd.qcut(data['Item_MRP'], 4,).unique()\n",
    "    data['Item_MRP'] = pd.qcut(data['Item_MRP'], 4, labels = [1, 2, 3, 4])\n",
    "    \n",
    "    # Se utiliza una copia de data para separar los valores codificados en un dataframe distinto.\n",
    "    \n",
    "    dataframe = data.drop(columns=['Item_Type', 'Item_Fat_Content']).copy()\n",
    "    \n",
    "    # Codificación de variables ordinales\n",
    "    dataframe['Outlet_Size'] = dataframe['Outlet_Size'].replace({'High': 2, 'Medium': 1, 'Small': 0})\n",
    "    dataframe['Outlet_Location_Type'] = dataframe['Outlet_Location_Type'].replace({'Tier 1': 2, 'Tier 2': 1, 'Tier 3': 0}) # Estas categorias se ordenaron asumiendo la categoria 2 como más lejos\n",
    "    \n",
    "    #FEATURES ENGINEERING: Codificación de variables nominales\n",
    "    dataframe = pd.get_dummies(dataframe, columns=['Outlet_Type'])\n",
    "    \n",
    "    # Eliminación de variables que no contribuyen a la predicción por ser muy específicas\n",
    "    dataset = dataframe.drop(columns=['Item_Identifier', 'Outlet_Identifier'])\n",
    "\n",
    "    # División del dataset de train y test\n",
    "    df_train = dataset.loc[data['Set'] == 'train']\n",
    "    df_test = dataset.loc[data['Set'] == 'test']\n",
    "\n",
    "    # Eliminando columnas sin datos\n",
    "    df_train.drop(['Set'], axis=1, inplace=True)\n",
    "    df_test.drop(['Item_Outlet_Sales','Set'], axis=1, inplace=True)\n",
    "\n",
    "    # Guardando los datasets\n",
    "    df_train.to_csv(\"train_final.csv\", index=False)\n",
    "    df_test.to_csv(\"test_final.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "aa11d4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('../data/Train_BigMart.csv') \n",
    "data_test = pd.read_csv('../data/Test_BigMart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bb786928",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AF01975\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "x = up_preprocesing(data_train, data_test)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dc2bf3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "81dcd8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_process(train):\n",
    "    df_train = pd.read_csv(train)\n",
    "    seed = 28\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # División de dataset de entrenaimento y validación\n",
    "    X = df_train.drop(columns='Item_Outlet_Sales')#[['Item_Weight', 'Item_MRP', 'Outlet_Establishment_Year', 'Outlet_Size', 'Outlet_Location_Type']] # .drop(columns='Item_Outlet_Sales')\n",
    "    x_train, x_val, y_train, y_val = train_test_split(X, df_train['Item_Outlet_Sales'], test_size = 0.3, random_state=seed)\n",
    "\n",
    "    # Entrenamiento del modelo\n",
    "    model.fit(x_train,y_train)\n",
    "\n",
    "    # Predicción del modelo ajustado para el conjunto de validación\n",
    "    pred = model.predict(x_val)\n",
    "\n",
    "    # Cálculo de los errores cuadráticos medios y Coeficiente de Determinación (R^2)\n",
    "    mse_train = metrics.mean_squared_error(y_train, model.predict(x_train))\n",
    "    R2_train = model.score(x_train, y_train)\n",
    "    print('Métricas del Modelo:')\n",
    "    print('ENTRENAMIENTO: RMSE: {:.2f} - R2: {:.4f}'.format(mse_train**0.5, R2_train))\n",
    "\n",
    "    mse_val = metrics.mean_squared_error(y_val, pred)\n",
    "    R2_val = model.score(x_val, y_val)\n",
    "    print('VALIDACIÓN: RMSE: {:.2f} - R2: {:.4f}'.format(mse_val**0.5, R2_val))\n",
    "\n",
    "    print('\\nCoeficientes del Modelo:')\n",
    "    # Constante del modelo\n",
    "    print('Intersección: {:.2f}'.format(model.intercept_))\n",
    "\n",
    "    # Coeficientes del modelo\n",
    "    coef = pd.DataFrame(x_train.columns, columns=['features'])\n",
    "    coef['Coeficiente Estimados'] = model.coef_\n",
    "    print(coef, '\\n')\n",
    "    \n",
    "    with open('model.pkl', 'wb') as archivo_pkl:\n",
    "        pickle.dump(model, archivo_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "03dd8be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas del Modelo:\n",
      "ENTRENAMIENTO: RMSE: 1169.35 - R2: 0.5284\n",
      "VALIDACIÓN: RMSE: 1146.66 - R2: 0.5526\n",
      "\n",
      "Coeficientes del Modelo:\n",
      "Intersección: 253.70\n",
      "                        features  Coeficiente Estimados\n",
      "0                    Item_Weight              -2.332949\n",
      "1                Item_Visibility            -311.774516\n",
      "2                       Item_MRP             825.276595\n",
      "3      Outlet_Establishment_Year             -10.632046\n",
      "4                    Outlet_Size             102.518103\n",
      "5           Outlet_Location_Type              27.760861\n",
      "6      Outlet_Type_Grocery Store           -1664.691331\n",
      "7  Outlet_Type_Supermarket Type1             191.570173\n",
      "8  Outlet_Type_Supermarket Type2            -242.596116\n",
      "9  Outlet_Type_Supermarket Type3            1715.717274 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = training_process(\"train_final.csv\")\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "64cb278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(data, modelo):\n",
    "    #Feature engineering años del establecimiento\n",
    "    data = pd.read_csv(data)\n",
    "    data['Outlet_Establishment_Year'] = 2020 - data['Outlet_Establishment_Year']\n",
    "    \n",
    "    #LIMPIEZA: Unificando etiquetas para 'Item_Fat_Content'\n",
    "    \n",
    "    data['Item_Fat_Content'] = data['Item_Fat_Content'].replace({'low fat':  'Low Fat', 'LF': 'Low Fat', 'reg': 'Regular'})\n",
    "    \n",
    "    #LIMPIEZA: de faltantes en el peso de los productos\n",
    "    \n",
    "    productos = list(data[data['Item_Weight'].isnull()]['Item_Identifier'].unique())\n",
    "    for producto in productos:\n",
    "        moda = (data[data['Item_Identifier'] == producto][['Item_Weight']]).mode().iloc[0,0]\n",
    "        data.loc[data['Item_Identifier'] == producto, 'Item_Weight'] = moda\n",
    "    \n",
    "    #LIMPIEZA: de faltantes en el tamaño de las tiendas\n",
    "    outlets = list(data[data['Outlet_Size'].isnull()]['Outlet_Identifier'].unique())\n",
    "    for outlet in outlets:\n",
    "        data.loc[data['Outlet_Identifier'] == outlet, 'Outlet_Size'] =  'Small'\n",
    "    \n",
    "    # FEATURES ENGINEERING: creando categorías para 'Item_Type'\n",
    "    data['Item_Type'] = data['Item_Type'].replace({'Others': 'Non perishable', 'Health and Hygiene': 'Non perishable', 'Household': 'Non perishable',\n",
    "     'Seafood': 'Meats', 'Meat': 'Meats',\n",
    "     'Baking Goods': 'Processed Foods', 'Frozen Foods': 'Processed Foods', 'Canned': 'Processed Foods', 'Snack Foods': 'Processed Foods',\n",
    "     'Breads': 'Starchy Foods', 'Breakfast': 'Starchy Foods',\n",
    "     'Soft Drinks': 'Drinks', 'Hard Drinks': 'Drinks', 'Dairy': 'Drinks'})\n",
    "\n",
    "    # FEATURES ENGINEERING: asignación de nueva categorías para 'Item_Fat_Content'\n",
    "    data.loc[data['Item_Type'] == 'Non perishable', 'Item_Fat_Content'] = 'NA'\n",
    "    \n",
    "    #FEATURES ENGINEERING: Codificando los niveles de precios de los productos\n",
    "    intervalos = [(31.289, 94.012), (94.012, 142.247), (142.247, 185.856),(185.856, 266.888)]\n",
    "    valores_asignados = [1, 2, 3, 4]\n",
    "\n",
    "    # Crear una nueva columna que contenga los valores asignados según los intervalos\n",
    "    data['Item_MRP'] = pd.cut(data['Item_MRP'], bins=[intervalo[0] for intervalo in intervalos] + [float('inf')], labels=valores_asignados, right=False)\n",
    "    \n",
    "    # Se utiliza una copia de data para separar los valores codificados en un dataframe distinto.\n",
    "    \n",
    "    dataframe = data.drop(columns=['Item_Type', 'Item_Fat_Content']).copy()\n",
    "    \n",
    "    # Codificación de variables ordinales\n",
    "    dataframe['Outlet_Size'] = dataframe['Outlet_Size'].replace({'High': 2, 'Medium': 1, 'Small': 0})\n",
    "    dataframe['Outlet_Location_Type'] = dataframe['Outlet_Location_Type'].replace({'Tier 1': 2, 'Tier 2': 1, 'Tier 3': 0}) # Estas categorias se ordenaron asumiendo la categoria 2 como más lejos\n",
    "    \n",
    "    #FEATURES ENGINEERING: Codificación de variables nominales\n",
    "    todos_valores = ['Grocery Store', 'Supermarket Type1', 'Supermarket Type2', 'Supermarket Type3']\n",
    "\n",
    "    # Agregar columnas dummy faltantes con valores inicializados en 0\n",
    "    for valor in todos_valores:\n",
    "        dataframe[f'Outlet_Type_{valor}'] = 0\n",
    "\n",
    "    # Marcar con 1 la columna correspondiente al valor presente en el registro de ejemplo\n",
    "    dataframe.loc[0, f'Outlet_Type_{dataframe[\"Outlet_Type\"].iloc[0]}'] = 1\n",
    "\n",
    "    \n",
    "    # Eliminación de variables que no contribuyen a la predicción por ser muy específicas y por repetición(\"outlet_type\")\n",
    "    dataset = dataframe.drop(columns=['Item_Identifier', 'Outlet_Identifier',\"Outlet_Type\"])\n",
    "    print(dataset)\n",
    "    \n",
    "    \n",
    "    with open(modelo, 'rb') as archivo_pkl:\n",
    "        modelo_cargado = pickle.load(archivo_pkl)\n",
    "        \n",
    "    \n",
    "    prediction = modelo_cargado.predict(dataset)\n",
    "    \n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "806756ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Item_Weight  Item_Visibility Item_MRP  Outlet_Establishment_Year  \\\n",
      "0        20.75         0.007565        2                         21   \n",
      "\n",
      "   Outlet_Size  Outlet_Location_Type  Outlet_Type_Grocery Store  \\\n",
      "0            1                     2                          0   \n",
      "\n",
      "   Outlet_Type_Supermarket Type1  Outlet_Type_Supermarket Type2  \\\n",
      "0                              1                              0   \n",
      "\n",
      "   Outlet_Type_Supermarket Type3  \n",
      "0                              0  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1979.827531\n",
       "Name: pred_Sales, dtype: float64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = \"df.csv\"\n",
    "b = prediction(df,'model.pkl')\n",
    "b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
